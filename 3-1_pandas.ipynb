{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Intro\n",
    "\n",
    "## DataFrames\n",
    "\n",
    "Pandas is a module for working with tables. The most important data structure in Pandas is the DataFrame, which you can think of as being similar to an Excel table, or an SQL table. Let's import the Pandas module and create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'col_1': [6,7,11], 'col_2': ['a', 'b', 'c']})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a dataframe called ``df``. It contains two variables (columns) and three observations (rows). In this case, we created the DataFrame using a dictionary, where the keys in the dictionary become the column names in the DataFrame, and the values in the dictionary become the data within each column.\n",
    "\n",
    "Note that DataFrames always have an index column, shown in the above output as the leftmost column (in this case the index contains the values 0, 1, and 2). If you do not specify an index when you create a DataFrame, Pandas will create an auto-incrementing index for you.\n",
    "\n",
    "Now let's create a DataFrame that looks a little more like real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'name': ['Jeff', 'Julia', 'Ronda', 'Dinesh', 'Susan'],\n",
    "    'height': [183, 176, 187, 157],\n",
    "    'weight': [69, 73, np.nan, 77, 82],\n",
    "    'gender': ['m', 'f', 'f', 'm', 'f']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have five observations across four variables. Note that one of the weight observations is a missing value, which in Pandas is conventionally represented by the NaN value (\"Not a Number\").\n",
    "\n",
    "The above DataFrame ``df`` was created by converting a Python Dictionary object into a Pandas DataFrame object. Note that you can also specify the columns and observations (rows) separately when creating a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "])\n",
    "print(a)\n",
    "print(type(a))\n",
    "\n",
    "# Create DataFrame using a Numpy array and specifying column names\n",
    "df_fromarray = pd.DataFrame(a, columns=['x', 'y', 'z'])\n",
    "print(df_fromarray)\n",
    "print(type(df_fromarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create another dataframe that contains identical columns and observations to ``df_fromarray``, but use a dictionary rather than an array to create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = # Write your dictionary code here...\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame using a dictionary\n",
    "df_fromdict = # Write your code here...\n",
    "\n",
    "\n",
    "assert df_fromarray.equals(df_fromdict), 'The DataFrames are not identical'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ``.equals()`` method in the code above is used to check if two DataFrames are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Series class, and selecting DataFrame columns\n",
    "\n",
    "Another important data structure in Pandas is the Series, which is like a single column of an Excel table. You can also think of them as being very similar to Array data structure in Numpy, although with a bit more flexible.\n",
    "\n",
    "Let's create a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([39, 43, 25])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we select a particular column of a DataFrame, it returns a Series object, not a DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we select multiple columns, a DataFrame is returned, not a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[['name', 'height']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also select a column of a DataFrame using slightly different syntax: ``df.col_name``, rather than ``df['col_name']``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use either syntax, but note that the ``.`` syntax is slightly more limited, because it requires that the column name contain only letters, numbers, and underscores; i.e. no whitespace or other special characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful DataFrame attributes and methods\n",
    "\n",
    "DataFrames have a number of useful attributes and methods. Some that you might find useful are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides information on dataframe variables (columns), numbers of observations (rows), and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the shape of a DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the column names of the DataFrame\n",
    "df.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the index of the DataFrame\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.unique()`` Series method gives the unique values in a DataFrame column (Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.value_counts()`` Series method can be used to count instances of each unique value in a DataFrame column (Series). For example, we can use it to count instances of each unique value in the ``'gender'`` column of ``df``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count instances of each unique value in a column\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple descriptive statistics for each column (of numeric or object data type)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive statistics included in the ``.describe()`` DataFrame method are:\n",
    "\n",
    "- **count:** count of the number of non-NA/null observations,\n",
    "- **mean:** mean of the values,\n",
    "- **std:** standard deviation of the observations,\n",
    "- **min:** minimum of the values,\n",
    "- **max:** maximum of the values,\n",
    "- the 25th, 50th (median), and 75th percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows\n",
    "\n",
    "We can select particular rows in a DataFrame which satisfy a given condition, using either of the following syntax options:\n",
    "\n",
    "- ``df[condition]``\n",
    "- ``df.loc[condition]``\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['name'] == 'Julia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'] = 'Julia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a new DataFrame of any rows that match the condition within ``[...]``. So depending on the search condition, we can also return multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gender'] == 'f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple conditions must be contained by brackets ``(...)`` and separated by ``&`` for the AND operator, ``|`` for the OR operator, etc...\n",
    "\n",
    "Write a line in the cell below that selects rows for women that are > 180cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[... your code here ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change the above to an OR operator (``|``) rather than an AND operator (``&``), and re-run the above cell. It should now select all rows where gender is female or height is > 180cm.\n",
    "\n",
    "Now try selecting all data other than Ronda's data using the NOT EQUALS operator (``!=``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[... your code here ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also assign any returned DataFrame to a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_rows = df[df['name'].str.startswith('J')]\n",
    "print(j_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to understand how Pandas identifies and returns the above rows. The query ``df[df['gender'] == 'f']`` actually contains a couple of different steps. First, the condition ``df['gender'] == 'f'`` grabs the \"gender\" column and returns the *indices* of all rows that have the value \"f\" in that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] == 'f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a Series of Boolean values (True of False) that identify whether each row satisfies the condition. This Series is then used to return all rows where the condition is True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gender'] == f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if we provide a list of Bool values, we would get the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading DataFrames\n",
    "\n",
    "Pandas has inbuilt functions that make it easy to save dataframes and load datasets of different formats into dataframes. One of the most common data formats is the comma-separated variable (CSV) format, where each row is an observation, and each variable in that row is separated by a comma. We can save our ``df`` DataFrame to disk as a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'height_weight.csv'\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load the same DataFrame, assigning it to a different variable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this has an extra column ``'Unnamed: 0'``. This was loaded because the ``.to_csv()`` method will automatically save the DataFrame's index to the CSV file as a new column, in addition to all other data.\n",
    "\n",
    "To prevent this, we need to specify ``index=False`` as an option when calling the ``.to_csv()`` method. Add the ``index=False`` option to the ``.to_csv()`` call above and re-run that cell. Then re-run the subsequent cell containing the ``.read_csv()`` call. It should now load a dataframe without the ``'Unnamed: 0'`` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Create a DataFrame called ``volumes`` with:\n",
    "- a single column called ``'radius (m)'``,\n",
    "- 20 rows, each with a radius value randomly chosen from between the bounding values 3.0 and 10.0. You can use Numpy's``np.random.uniform(low=a, high=b, size=(n,))`` function, which returns an array of ``n`` randomly generated numbers drawn from a uniform distribution between the numbers ``a`` and ``b``.\n",
    "\n",
    "Create a new column called ``'sphere_vol (m^3)'`` containing the corresponding volume of a sphere for each of the radius values. The formula for calculating the volume of a sphere is:\n",
    "\n",
    "$V = {4 \\over 3} \\pi r^3$\n",
    "\n",
    "Note that the value for $\\pi$ is available in Numpy using the ``np.pi`` variable.\n",
    "\n",
    "Now print only the rows where the volume is > $30 m^3$.\n",
    "\n",
    "Save the ``volumes`` DataFrame to the location ``'../data/volumes.csv'``. Then load the data into a new DataFrame called ``vol`` and check that it is equivalent to the ``volumes`` DataFrame. If the DataFrames are not equivalent, one possibility is that floating point rounding errors have created slightly different floats in the new dataframe. One way to check this is by rounding all float values in each dataframe to, say, 5 decimal places using the ``df.round()`` method, and then performing the comparison between the rounded dataframes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
